\documentclass{automatextcc}

% Caminho da Pasta das Figuras
\graphicspath{{figuras/}}

%\makeindex  Opcional (Índice Remissivo)


\begin{document}


\title{Composição Automática de Músicas utilizando Redes Neurais Recorrentes}
\author{Nicolas Mathias Hahn}

% orientador(a) do trabalho {nome}{Orientador(a)}
\advisor{Prof. Dr. Guilherme Pumi}{Orientador}
% universidade onde obteve o título e atual
\advisorinfo{Doutor pela Universidade Federal do Rio Grande do Sul, Porto Alegre, RS}{UFRGS}

% banca examinadora:
\examinera{Prof. Dr. xxx}
\examinerainfo{Doutor pela XX -- Cidade, Estado}{Universidade}

% departamento:
\dept{\DEST}

% data de entrega:
\date{Outubro de 2022}


% Capa
\maketitulo

% Folha de rosto
\makefolhaderosto

% Folha de aprovação
\makefolhadeaprovacaoA % Um membro na banca
%\makefolhadeaprovacaoB % Dois membros na banca


% Epígrafe (OPCIONAL)
\newpage
\vspace*{\fill}
\begin{flushright} % mexer aqui
	\textit{``Since I have always preferred making plans to executing them, I have gravitated towards situations and systems that, once set into operation, could create music with little or no intervention on my part. That is to say, I tend towards the roles of planner and programmer, and then become an audience to the results.''} \newline
	\textit{Brian Eno \citep{alpern1995}}.
\end{flushright}

% Agradecimentos
\newpage
\chapter*{Agradecimentos}
Agradeço a xxx. Opcional % mexer aqui

% palavras chave
    % português
\keyword{Redes Neurais}
\keyword{Música}
    % inglês
\keyworde{Neural Networks}
\keyworde{Music}

% resumo 
    % português
\begin{abstract}
Este trabalho ....
\end{abstract}
    % inglês
\begin{englishabstract}
In this work ....
\end{englishabstract}

% sumário (Obrigatório)
\tableofcontents

% lista de ilustrações (Obrigatório)
\listoffigures

% lista de tabelas (Obrigatório)
\listoftables

% se um pato perde a pata, ele fica manco ou viúvo???

% Regras do PUMI:
%  * vamos ver a introdução por último
%  * deixar em bullets os itens que pretende falar
%  * focar na fundamentação teórica (redes neurais, RNN e LSTM)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%  Introdução
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introdução}

\begin{itemize}
    \item composição algorítmica (composição automática) - caminhar histórico?
    \item formas de composição algorítmica: rule-based, stochastic e AI
\end{itemize}

% certamente olhar este artigo e suas bibliografias:
% https://ccrma.stanford.edu/~blackrse/algorithm.html

% talvez olhar este artigo:
% https://musica.ufmg.br/nasnuvens/wp-content/uploads/2020/11/2016-38-A-interatividade-nas-trilhas-sonoras-de-jogos-digitais-e-um-comparativo-com-a-música-de-cinema.pdf



% referencial teórico
\chapter{Referencial Teórico}

    % NN
\section{Redes Neurais Artificiais - ANN}

    % parágrafo retirado de \citep{aggarwal2018DeepLearning}
Redes neurais artificiais, ou apenas redes neurais, são populares técnicas de \textit{machine learning} que simulam o mecanismo de aprendizagem dos organismos biológicos. Os neurônios são conectados uns aos outros por meio de axônios e dendritos, e as regiões de conexão entre ambos é referida como sinapse. A força das conexões sinápticas usualmente muda em reposta ao estímulo externo. Essa troca é como a aprendizagem acontece em organismos vivos \citep{aggarwal2018DeepLearning}. 

    % itens abaixo retirados de \citet{haykin2001redesneurais}
De acordo com \citet{haykin2001redesneurais}, o modelo de um neurônio forma a base para o projeto de redes neurais (artificiais). Podemos identificar três elementos básicos do modelo neuronal:

\begin{enumerate}
    \item Um conjunto de sinapses, cada uma caracterizada por um peso/força própria. Especificamente, um sinal $x_j$ na entrada da sinapse $j$ conectada ao neurônio $k$ é multiplicado por cada peso sináptico $w_{kj}$. O peso sináptico de um neurônio artificial pode estar em um intervalo que inclui valores positivos e negativos.
    \item Um \textit{somador} para somar os sinais de entrada, ponderados pelas respectivas sinapses de cada neurônio, constituindo uma \textit{combinação linear}.
    \item Uma \textit{função de ativação} para restringir a amplitude de saída de um neurônio (fixando em um valor finito). Tipicamente, o intervalo normalizado é escrito como $[0,1]$ ou $[-1,1]$.
\end{enumerate}

Além disso, também é incluído um \textit{bias} (viés) no modelo, representado por $b_k$. Esse \texit{bias} tem o efeito de aumentar/diminuir a entrada líquida da função de ativação, dependendo se ele é positivo ou negativo. 

Matematicamente, podemos descrever um neurônio $k$ escrevendo o seguinte par de equações:

\begin{equation}
    \mu_k = \sum_{j=1}^{m} w_{kj}x_j
\end{equation}

e

\begin{equation}
    y_k = \varphi(\mu_k + b_k)
\end{equation}

em que $x_1,x_2,\dots,x_m$ são os sinais de entrada, $w_{k1},w_{k2},\dots,w_{km}$ são os pesos sinápticos do neurônio $k$; $\mu_k$ é a saída da combinação linear devida aos sinais de entrada; $b_k$ é o \textit{bias}; $\varphi(\cdot)$ é a função de ativação; e $y_k$ é o sinal de saída do neurônio.


% Obs.:
% - faltam definições de camada oculta e deep learning
% - faltam polimentos nos textos
% - faltam inserir gráficos
% - inserir/citar mais bibliografias?
% - comentar sobre arquiteturas?



        % função de ativação
\subsection{Função de Ativação}
    % funções de ativação coletadas de \citep{dsa2021deeplearningbook}
O objetivo da função de ativação é determinar se o neurônio de uma rede neural será ativado ou não. Ou seja, se a informação que o neurônio está recebendo é fornecida ou deve ser ignorada \citep{dsa2021deeplearningbook}.

Existem diversas funções de ativação:

\begin{itemize}
    \item Etapa Binária: $f(x) = 1, \; x>=0$; $f(x) = 0, \; x<0$ 
    \item Linear: $f(x) = \alpha x, \; \alpha \in \mathbb{R}$
    \item Sigmóide: $f(x) = \frac{1}{1+e^{-x}}$ 
    \item Tangente Hiperbólica (tanh): $f(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$
    \item ReLU: $f(x) = max(0,x)$
    \item Leaky ReLU: $f(x) = \alpha x \; x<0, \alpha \in \mathbb{R}$; $f(x) = x \; x>=0$
\end{itemize}

% Obs.:
% - falta inserir gráficos
% - desenvolver mais o texto e inserir mais citações/bibliografias?
% https://matheusfacure.github.io/2017/07/12/activ-func/


    % RNN 
\subsection{Redes Neurais Recorrentes - RNN}
    % texto abaixo inserido com base em \citet{mit2016deeplearningbook}
De acordo com \citet{mit2016deeplearningbook}, RNN's são uma família de redes neurais para o processamento de dados sequenciais, ou seja, uma sequência de valores $x_1,\dots,x_n$. Diferentemente de uma rede multicamadas, em que há parâmetros específicos para cada índice de tempo $t, \; t=1,\dots,T$, é realizado um compartilhamento dos parâmetros (consequentemente, mesmos pesos ao longo de diversos passos de tempos), o que possibilita estender e aplicar o modelo a exemplos e generalizá-lo através deles. Tal compartilhamento é importante quando um pedaço particular de informação pode ocorrer em diversas posições em uma sequência. 

% Obs.:
% - falta bastante leitura para eu entender melhor isso
% - bibliografias com outras formas de explicação




% https://en.wikipedia.org/wiki/Recurrent_neural_network
% https://www.ibm.com/cloud/learn/recurrent-neural-networks

%\subsubsection{CharRNN}
%\subsubsection{Long Short-Term Memory - LSTM}
% explicar a arquitetura da rede (com imagens)

    % notação ABC
\section{Notação ABC}

    % texto baseado no 'about' do site oficial do criador: abcnotation.com
ABC é uma linguagem desenvolvida para notação musical apenas em formato texto. Um dos principais intuitos da linguagem, o que acaba a diferindo de outras linguagens de computadores, é que ela é bastante concisa e pode ser facilmente lida por humanos. Em outras palavras, é possível tocar uma peça musical diretamente da notação ABC, sem o processo de impressão ou conversão. 

Desde sua introdução ao final de 1993 por Chris Walshaw, se tornou muito popular e existem agora vários programas (para sistemas operacionais diversos, como Windows, MacOS, Unix e mesmo para PDAs) que podem ler notação ABC, convertendo-a em partitura ou tocando-a através de alto-falantes de um computador. Além disso, existem centenas de milhares de músicas em ABC, em uma variedade de coleções online históricas e contemporâneas.


% Obs:
% - inserir imagem/explicacoes do formato
% fonte: https://abcnotation.com/about (site oficial do criador da linguagem)
% inserir na bibliografia (como inserir website?)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%  Metodologia
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Metodologia}

% coleta de dados
\section{Coleta de Dados}

% resumo como foram coletados os dados (fonte também) e que isso resultou em error 403 (acesso negado) no site hehe

A coleta de dados foi realizada por meio de um \textit{crawler/bot}, desenvolvido na linguagem \href{https://python.org/}{Python}, para extrair músicas em formato \textit{.abc} do site \href{https://abcnotation.com/}{``abcnotation.com''}. Após uma semana de execução, foram obtidos 184.900 arquivos contendo diversas informações sobre as peças musicais (como título, autor, tonalidade, entre outras).

% tratamento de dados
\section{Tratamento de Dados}

% explicar a forma que tratei os arquivos .abc:
%   - removi títulos
%   - removi letras das músicas
%   - removi caracteres de comentários
%   - codifiquei/vetorizei as strings para que fosse possível ir e vir (caractere --> index e vice-versa)

% rede neural
\section{Rede Neural}
    % arquitetura
\subsection{Arquitetura}
    % parâmetros de treinamento
\subsection{Parâmetros de Treinamento}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%  Resultados
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Resultados}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%  Conclusão
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusão}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%  Referências
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\addcontentsline{toc}{chapter}{Referências Bibliográficas} % Coloca no sumário
\bibliographystyle{apalike-br}
\bibliography{biblio}


%\printindex % Opcional  Índice remissivo

\end{document}
