{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CÃ³digo Base\n",
    "link: https://goodboychan.github.io/python/tensorflow/mit/2021/02/14/music-generation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import regex as re\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "assert len(tf.config.list_physical_devices('GPU')) > 0\n",
    "\n",
    "# from library.reader import *\n",
    "# from library.models import *\n",
    "\n",
    "# global_seed = 301831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_song_snippet(text):\n",
    "    pattern = '(^|\\n\\n)(.*?)\\n\\n'\n",
    "    search_results = re.findall(pattern, text, overlapped=True, flags=re.DOTALL)\n",
    "    songs = [song[1] for song in search_results]\n",
    "    return songs\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "songs = []\n",
    "\n",
    "with open(os.path.join(cwd, 'data', 'irish', 'irish.abc'), 'r') as f:\n",
    "    text = f.read()\n",
    "    songs = extract_song_snippet(text)\n",
    "    \n",
    "# Print one of the songs to inspect it in greater detail!\n",
    "example_song = songs[0]\n",
    "print(\"\\nExample song: \")\n",
    "print(example_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocab(text):\n",
    "    vocab = sorted(set(text))\n",
    "    return {u:i for i, u in enumerate(vocab)}\n",
    "\n",
    "songs_joined = \"\\n\\n\".join(songs) \n",
    "\n",
    "# Find all unique characters in the joined string\n",
    "vocab = extract_vocab(songs_joined)\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the dataset for the learning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2idx(string, vocab=None):\n",
    "    if vocab==None:\n",
    "        vocab = extract_vocab(string)\n",
    "    vectorized_list = np.array([vocab[s] for s in string])\n",
    "    return vectorized_list\n",
    "\n",
    "def idx2char(idx, vocab):\n",
    "    keys = list(vocab.keys())\n",
    "    string = ''\n",
    "    if isinstance(idx, collections.Iterable):\n",
    "        for i in idx:\n",
    "            string += keys[i]\n",
    "    else:\n",
    "        string += keys[idx]\n",
    "    return string\n",
    "\n",
    "\n",
    "vectorized_songs = char2idx(songs_joined, vocab)\n",
    "\n",
    "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
    "# check that vectorized_songs is a numpy array\n",
    "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training examples and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(vectorized_songs, seq_length, batch_size, seed=None):\n",
    "    n = vectorized_songs.shape[0] - 1\n",
    "    #np.random.seed(seed)\n",
    "    idx = np.random.choice(n-seq_length, batch_size)\n",
    "    input_batch = [vectorized_songs[i:i+seq_length] for i in idx]\n",
    "    output_batch = [vectorized_songs[i+1: i+1+seq_length] for i in idx]\n",
    "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "    y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "    return x_batch, y_batch\n",
    "\n",
    "for j in range(5):\n",
    "    x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1, seed=1+j)\n",
    "    print(str(j)+' ---------------------------------------------------------------------------------')\n",
    "    for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
    "        print(\"Step {:3d}\".format(i))\n",
    "        print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char(input_idx,vocab))))\n",
    "        print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char(target_idx,vocab))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_LSTM(vocab_size, embedding_dim, rnn_units, batch_size, seed=None,\n",
    "                     rnn_init='glorot_uniform', rnn_activation='sigmoid'):\n",
    "    #tf.random.set_seed(seed)\n",
    "    model = tf.keras.Sequential([\n",
    "        # layer 1: inputs\n",
    "        tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            batch_input_shape=[batch_size, None]\n",
    "        ),\n",
    "        # layer 2: LSTM\n",
    "        tf.keras.layers.LSTM(\n",
    "            rnn_units, \n",
    "            recurrent_initializer=rnn_init,\n",
    "            recurrent_activation=rnn_activation,\n",
    "            return_sequences=True,\n",
    "            stateful=True,\n",
    "        ),\n",
    "        # layer 3: dense fully-connected layer that transforms the LSTM output into the vocabulary size\n",
    "        tf.keras.layers.Dense(\n",
    "            units=vocab_size\n",
    "        )\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build a simple model with default hyperparameters. You will get the \n",
    "#   chance to change these later.\n",
    "model = build_model_LSTM(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32, seed=1)\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32, seed=3)\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "print()\n",
    "\n",
    "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char(x[0],vocab))))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char(sampled_indices,vocab))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model: loss and training operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(labels, logits):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "    return loss\n",
    "\n",
    "example_batch_loss = compute_loss(y, pred) \n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters:\n",
    "num_training_iterations = 1000  # Increase this to train longer\n",
    "batch_size = 4  # Experiment between 1 and 64\n",
    "seq_length = 100  # Experiment between 50 and 500\n",
    "learning_rate = 5e-3  # Experiment between 1e-5 and 1e-1\n",
    "\n",
    "# Model parameters: \n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256 \n",
    "rnn_units = 1024  # Experiment between 1 and 2048\n",
    "\n",
    "# Checkpoint location: \n",
    "checkpoint_dir = './training_checkpoints2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicPlotter:\n",
    "  def __init__(self, sec, xlabel='', ylabel='', scale=None):\n",
    "\n",
    "    self.xlabel = xlabel\n",
    "    self.ylabel = ylabel\n",
    "    self.sec = sec\n",
    "    self.scale = scale\n",
    "\n",
    "    self.tic = time.time()\n",
    "\n",
    "  def plot(self, data):\n",
    "    if time.time() - self.tic > self.sec:\n",
    "      plt.cla()\n",
    "\n",
    "      if self.scale is None:\n",
    "        plt.plot(data)\n",
    "      elif self.scale == 'semilogx':\n",
    "        plt.semilogx(data)\n",
    "      elif self.scale == 'semilogy':\n",
    "        plt.semilogy(data)\n",
    "      elif self.scale == 'loglog':\n",
    "        plt.loglog(data)\n",
    "      else:\n",
    "        raise ValueError(\"unrecognized parameter scale {}\".format(self.scale))\n",
    "\n",
    "      plt.xlabel(self.xlabel); plt.ylabel(self.ylabel)\n",
    "      ipythondisplay.clear_output(wait=True)\n",
    "      ipythondisplay.display(plt.gcf())\n",
    "\n",
    "      self.tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_LSTM(vocab_size, embedding_dim, rnn_units, batch_size, seed=1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = model(x)\n",
    "        loss = compute_loss(y, y_hat)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "##################\n",
    "# Begin training!#\n",
    "##################\n",
    "\n",
    "history = []\n",
    "plotter = PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "\n",
    "  # Grab a batch and propagate it through the network\n",
    "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size, seed=1+iter)\n",
    "  loss = train_step(x_batch, y_batch)\n",
    "\n",
    "  # Update the progress bar\n",
    "  history.append(loss.numpy().mean())\n",
    "  plotter.plot(history)\n",
    "\n",
    "  # Update the model with the changed weights!\n",
    "  if iter % 100 == 0:     \n",
    "    model.save_weights(checkpoint_prefix)\n",
    "    \n",
    "# Save the trained model and the weights\n",
    "model.save_weights(checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate music using the RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_LSTM(vocab_size, embedding_dim, rnn_units, batch_size=1, seed=1)\n",
    "\n",
    "# Restore the model weights for the last checkpoint after training\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, vocab, choose, generation_length=None, n_songs=None, seed=None):\n",
    "    input_eval = char2idx(start_string, vocab)\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text = start_string\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    tqdm._instances.clear()\n",
    "\n",
    "    #tf.random.set_seed(seed)\n",
    "\n",
    "    if choose=='length': \n",
    "        n = generation_length\n",
    "        \n",
    "        for i in tqdm(range(n)):\n",
    "            pred = model(input_eval)[0]\n",
    "            pred_id = tf.random.categorical(pred, num_samples=1)[-1,0].numpy()\n",
    "            input_eval = tf.expand_dims([pred_id],0)\n",
    "            text_generated.append(idx2char(pred_id, vocab))\n",
    "        \n",
    "        text = (start_string + ''.join(text_generated))\n",
    "    \n",
    "\n",
    "    if choose=='songs': \n",
    "        n = 0\n",
    "\n",
    "        with tqdm(total=n_songs):\n",
    "            while n < n_songs:\n",
    "                pred = model(input_eval)[0]\n",
    "                pred_id = tf.random.categorical(pred, num_samples=1)[-1,0].numpy()\n",
    "                input_eval = tf.expand_dims([pred_id],0)\n",
    "                text_generated.append(idx2char(pred_id, vocab))\n",
    "                text = start_string + ''.join(text_generated)\n",
    "                aux = extract_song_snippet(text)\n",
    "                n = len(aux)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TODO: Use the model and the function defined above to generate ABC format text of length 1000!\n",
    "    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
    "generated_text = generate_text(model, start_string='X:1\\nT:', vocab=vocab, choose='length', generation_length=1000, seed=1) # TODO\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_songs = extract_song_snippet(generated_text)\n",
    "print(generated_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rever get_batch (acho que problema tÃ¡ em usar seed)\n",
    "# rever fit_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tcc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8423169460a4ab7c0196f3b7f025b4f11bf11307ee8777457d830da4956ded6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
